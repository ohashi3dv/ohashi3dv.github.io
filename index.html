<!DOCTYPE html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155300148-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155300148-1');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Takuya Ohashi</title>
  <link href="./css/style.css" rel="stylesheet">
  <meta content='width=device-width,initial-scale=1' name='viewport'>
</head>


<div class="main">
<div class="container">
<section id="profile">
    <div style="text-align: right;">
    <a href="./index_ja.html">Japanese</a> / English
    </div>
<div class="profile_left">
  <!-- <span style="font-size: medium;"> -->
  <name>Takuya Ohashi</name> </br></br>
  I am a research engineer at SONY Corporation.</br></br>
  <u>Research Interests</u></br>
      <li>Computer Vision</li>
      <li>Machine Intelligence</li>
      <li>Markerless Motion Capture</li></br>
  <u>Contact</u></br>
    <span>Email: ohashi.ddd [at] gmail.com</span></br>
    <span>Facebook: <a href="https://www.facebook.com/takuya.ohashi.084">takuya.ohashi.084</a></span>
  <!-- </span> -->
</div>
<div class="profile_right">
</br><img src="./images/profile.jpg">
</div>
<div class="profile_bottom">
</div>
</section></br>

<p>Projects</p><hr>
<table width="100%" border="0">
  <tbody>
    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap-v2.gif"</td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
      Synergetic Reconstruction from 2D Pose and 3D Motion for Wide-Space Multi-Person Video Motion Capture in the Wild</strong><br>
      <u>Takuya Ohashi</u>, Yosuke Ikegami, Yoshihiko Nakamura<br>
      Image and Vision Computing, 101:103970, 2020<br>
      <a href="http://www.ynl.t.u-tokyo.ac.jp/research/vmocap-syn/">[Project page]</a> <a href="https://arxiv.org/pdf/2001.05613.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=IXdDND9cVDg">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/files/hp_vmocap_release_fix.pdf">[Press release]</a></p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap.gif"></td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
        VMocap: realtime video motion capture and analysis of human movements </strong><br>
        Yoshihiko Nakamura, Yosuke Ikegami, <u>Takuya Ohashi</u>, Hiroki Obara<br>
        2018<br>
        <a href="https://www.youtube.com/watch?v=K_D2nGcht_k">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/pdf/news_20180515.pdf">[Press release]</a> </p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap-v1.gif"></td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
      Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model</strong><br>
      <u>Takuya Ohashi</u>, Yosuke Ikegami, Kazuki Yamamoto, Wataru Takano, Yoshihiko Nakamura<br>
      IROS,2018<br>
      <font color="#ff0000"><em><strong>Best Paper Award, Finalists</strong></em></font></br>
      <a href="http://www.ynl.t.u-tokyo.ac.jp/research/vmocap/">[Project page]</a> <a href="https://arxiv.org/pdf/1912.03880.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=hakyUz3_SD4">[Video]</a></p></td>
    <td>&nbsp;</td>
    </tr>


</tbody></table>
<p><a href="https://scholar.google.co.jp/citations?user=kR0Dxl0AAAAJ">[Google Scholar]</a></p>
<br>


<p>Affiliation</p>
<hr>
<ul>
<li><span style="font-size: medium;">Jan 2021 - <strong>current</strong>: Research engineer, Tokyo Laboratory 19, SONY Corporation</span></li>
<li><span style="font-size: medium;">Nov 2018 - Dec 2020: Collaborative researcher, Dept. of Mechano-informatics, The University of Tokyo</span></li>
<li><span style="font-size: medium;">Apr 2018 - Dec 2020: Research engineer, Service Innovation Dept., NTT DOCOMO, Inc.</span></li>
<li><span style="font-size: medium;">Oct 2016 - Mar 2017: Exchange student, Dept. of Electrical Engineering and Information Technology, Technical University of Munich</span></li>
<li><span style="font-size: medium;">Oct 2015 - Mar 2018: Master's student, Dept. of Mechano-informatics, The University of Tokyo</span></li>
<li><span style="font-size: medium;">Apr 2015 - Sep 2015: Dept. of Mechanical and Control Engineering, Tokyo Institute of Technology</span></li>
<li><span style="font-size: medium;">Apr 2011 - Mar 2015: Undergraduate student, Dept. of Mechano-Aerospace Engineering, Tokyo Institute of Technology</span></li>
</ul>
<br clear="all">

<p>Education</p>
<hr>
<ul>
<li><span style="font-size: medium;">
Master's degree (Engineering in Mechano-Informatics) - Mar 2018</span>
<ul>
  <li>The University of Tokyo, Japan</li>
  <li>Adviser: Prof. Yoshihiko Nakamura</li>
</ul>
</li>
<li><span style="font-size: medium;">Bachelor's degree (Engineering in Mechanics) - Mar 2015</span>
<ul>
  <li>Tokyo Institute of Technology, Japan</li>
  <li>Adviser: Ass. Prof. Takatoki Yamamoto</li>
</ul>
</li>
</ul>
<br clear="all">


<p>Honors and Awards</p>
<hr>
<ul>
<li><span style="font-size: medium;">IROS 2018 Best Paper Award Finalists, 2018 <a href="https://www.iros2018.org/awards">[Link]</a></span></li>
<li><span style="font-size: medium;">Miura Award, The Japan Society of Mechanical Engineers, 2018 <a href="https://www.jsme.or.jp/archive/award/miura-17.pdf">[Link]</a></span></li>
</ul>
<br clear="all">


<p>Media</p>
<hr>
<ul>
<li><span style="font-size: medium;">『子供の科学 4月号』: 複数人のモーションキャプチャをカメラ映像だけで行う!? (Japanese), 2020 <a href="https://www.seibundo-shinkosha.net/magazine/kids/39165/">[Link]</a></span></li>
<li><span style="font-size: medium;">ITmedia NEWS (Seamless): カメラ映像から複数人の動きを骨格・筋レベルで同時検出　東大とドコモがモーションキャプチャ技術発表 (Japanese), 2020 <a href="https://www.itmedia.co.jp/news/articles/2001/30/news041.html">[Link]</a></span></li>
<li><span style="font-size: medium;">日経 xTECH special: あと１年に迫った5Gサービス開始 ドコモのイベントで未来を探ってみた (Japanese), 2019 <a href="https://special.nikkeibp.co.jp/atclh/NXT/19/nttdocomov0118_01/p2/">[Link]</a></span></li>
<li><span style="font-size: medium;">毎日新聞: ＡＩで全身運動を即座に可視化　東大チーム開発 (Japanese), 2018 <a href="https://mainichi.jp/articles/20180531/ddm/016/040/005000c">[Link]</a></span></li>
<li><span style="font-size: medium;">Seamless: 東京大学など、複数台のRGBカメラだけから人のモーションキャプチャをリアルタイムに行う技術「VMocap」を発表 (Japanese), 2018 <a href="https://shiropen.com/seamless/vmocap">[Link]</a></span></li>
</ul>
<br clear="all">


<p>Others</p>
<hr>
<ul>

</ul>
<br clear="all">


</div></div>
