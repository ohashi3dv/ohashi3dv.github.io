<!DOCTYPE html>
<!-- saved from url=(0034)http://www.cs.toronto.edu/~slwang/ -->
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155300148-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-155300148-1');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Takuya Ohashi</title>
  <link href="./css/style.css" rel="stylesheet">
  <meta content='width=device-width,initial-scale=1' name='viewport'>
</head>


<div class="main">
<div class="container">
<section id="profile">
    <div style="text-align: right;">
    <a href="./index_ja.html">Japanese</a> / English
    </div>
<div class="profile_left">
  <name>Takuya Ohashi</name> </br></br>
  I am a research engineer at NTT DOCOMO, Inc. I also work at the University of Tokyo as a joint-project researcher.</br></br>
  <u>Research Interests</u></br>
      <li>Computer Vision</li>
      <li>Machine Intelligence</li>
      <li>Markerless Motion Capture</li></br>
  <u>Contact</u></br>
    <span>Email: ohashi [at] ynl.t.u-tokyo.ac.jp</span></br>
    <span>Facebook: <a href="https://www.facebook.com/takuya.ohashi.084">takuya.ohashi.084</a></span>
</div>
<div class="profile_right">
</br><img src="./images/profile.jpg">
</div>
<div class="profile_bottom">
</div>
</section></br>

<p>Projects</p><hr>
<table width="100%" border="0">
  <tbody>
    <tr>
    <td width="30%" class="crown-jewel"><img src="./images/vmocap.gif" width="240"></td>
    <td width="4%"> </td>
    <td width="65%"><p><strong>
        VMocap: realtime video motion capture and analysis of human movements </strong><br>
        Yoshihiko Nakamura, Yosuke Ikegami, <u>Takuya Ohashi</u>, Hiroki Obara<br>
        2018<br>
        <a href="https://www.youtube.com/watch?v=K_D2nGcht_k">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/pdf/news_20180515.pdf">[Press release]</a> </p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="30%" class="crown-jewel"><img src="./images/vmocap-v1.gif" width="240"></td>
    <td width="4%"> </td>
    <td width="65%"><p><strong>
      Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model</strong><br>
      <u>Takuya Ohashi</u>, Yosuke Ikegami, Kazuki Yamamoto, Wataru Takano, Yoshihiko Nakamura<br>
      IROS,2018<br>
      <font color="#ff0000"><em><strong>Best Paper Award, Finalists</strong></em></font></br>
      <a href="https://roboticsynl.github.io/vmocap/">[Project page]</a> <a href="https://arxiv.org/pdf/1912.03880.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=hakyUz3_SD4">[Video]</a></p></td>
    <td>&nbsp;</td>
    </tr>


</tbody></table>
<p><a href="https://scholar.google.co.jp/citations?user=kR0Dxl0AAAAJ">[Google Scholor]</a></p>
<br>


<p>Affiliation</p>
<hr>
<ul>
<li><span style="font-size: medium;">Nov 2018 - <strong>current</strong>: Joint-project researcher, Dept. of Mechano-informatics, The University of Tokyo</span></li>
<li><span style="font-size: medium;">Apr 2018 - <strong>current</strong>: Research engineer, Service Innovation Dept., NTT DOCOMO, Inc.</span></li>
<li><span style="font-size: medium;">Oct 2016 - Mar 2017: Exchange student, Dept. of Electrical Engineering and Information Technology, Technical University of Munich</span></li>
<li><span style="font-size: medium;">Oct 2015 - Mar 2018: Master's student, Dept. of Mechano-informatics, The University of Tokyo</span></li>
<li><span style="font-size: medium;">Apr 2011 - Mar 2015: Undergraduate student, Dept. of Mechano-Aerospace Engineering, Tokyo Institute of Technology</span></li>
</ul>
<br clear="all">

<p>Education</p>
<hr>
<ul>
<li><span style="font-size: medium;">
Master's degree (Engineering in Mechano-Informatics) - Mar. 2018</a></span>
<ul>
  <li>The University of Tokyo, Japan</li>
  <li>Adviser: Yoshihiko Nakamura (Professor)</li>
</ul>
</li>
<li><span style="font-size: medium;">Bachelor's degree (Engineering in Mechanics) - Mar. 2015</a></span>
<ul>
  <li>Tokyo Institute of Technology, Japan</li>
  <li>Adviser: Takatoki Yamamoto (Associate Professor)</li>
</ul>
</li>
</ul>
<br clear="all">


<p>Honors and Awards</p>
<hr>
<ul>
<li><span style="font-size: medium;">IROS 2018 Best Paper Award, Finalists, 2018 <a href="https://www.iros2018.org/awards">[Link]</a></span></li>
<li><span style="font-size: medium;">The Japan Society of Mechanical Engineers Miura Award, 2017 <a href="https://www.jsme.or.jp/archive/award/miura-17.pdf">[Link]</a></span></li>
</ul>
<br clear="all">


<p>Media</p>
<hr>
<ul>
<li><span style="font-size: medium;">日経 xTECH special: あと１年に迫った5Gサービス開始 ドコモのイベントで未来を探ってみた (Japanese), 2019 <a href="https://special.nikkeibp.co.jp/atclh/NXT/19/nttdocomov0118_01/p2/">[Link]</a></span></li>
<li><span style="font-size: medium;">毎日新聞: ＡＩで全身運動を即座に可視化　東大チーム開発 (Japanese), 2018 <a href="https://mainichi.jp/articles/20180531/ddm/016/040/005000c">[Link]</a></span></li>
<li><span style="font-size: medium;">Seamless: 東京大学など、複数台のRGBカメラだけから人のモーションキャプチャをリアルタイムに行う技術「VMocap」を発表 (Japanese), 2018 <a href="https://shiropen.com/seamless/vmocap">[Link]</a></span></li>
</ul>
<br clear="all">


<p>Others</p>
<hr>
<ul>

</ul>
<br clear="all">


</div></div>
