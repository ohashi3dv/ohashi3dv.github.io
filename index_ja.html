<!DOCTYPE html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Takuya Ohashi</title>
  <link href="./css/style.css" rel="stylesheet">
  <meta content='width=device-width,initial-scale=1' name='viewport'>
</head>


<div class="main">
<div class="container">
<section id="profile">
    <div style="text-align: right;">
    Japanese / <a href="./index.html">English</a>
    </div>
<div class="profile_left">
  <!-- <span style="font-size: medium;"> -->
  <name>大橋拓也 (Takuya OHASHI)</name> </br></br>
  <u>所属</u></br>
    <li>ソニー株式会社</li>
</br>
  <u>研究分野</u></br>
      <li>コンピュータビジョン</li>
      <li>機械知能</li>
      <li>マーカーレスモーションキャプチャ</li></br>
  <u>連絡先</u></br>
    <span>Email: ohashi.ddd [at] gmail.com</span></br>
    <span>Facebook: <a href="https://www.facebook.com/takuya.ohashi.084">takuya.ohashi.084</a></span>
  <!-- </span> -->
</div>
<div class="profile_right">
</br><img src="./images/profile.jpg">
</div>
<div class="profile_bottom">
</div>
</section></br>

<p>研究プロジェクト</p><hr>
<table width="100%" border="0">
  <tbody>
    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap-v2.gif"</td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
        Synergetic Reconstruction from 2D Pose and 3D Motion for Wide-Space Multi-Person Video Motion Capture in the Wild</strong><br>
        <u>Takuya Ohashi</u>, Yosuke Ikegami, Yoshihiko Nakamura<br>
        Image and Vision Computing, 101:103970, 2020<br>
        <a href="http://www.ynl.t.u-tokyo.ac.jp/research/vmocap-syn/">[Project page]</a> <a href="https://arxiv.org/pdf/2001.05613.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=IXdDND9cVDg">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/files/hp_vmocap_release_fix.pdf">[Press release]</a></p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap.gif"></td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
        VMocap: realtime video motion capture and analysis of human movements </strong><br>
        Yoshihiko Nakamura, Yosuke Ikegami, <u>Takuya Ohashi</u>, Hiroki Obara<br>
        2018<br>
        <a href="https://www.youtube.com/watch?v=K_D2nGcht_k">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/pdf/news_20180515.pdf">[Press release]</a> </p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="32%" class="crown-jewel"><img src="./images/vmocap-v1.gif"></td>
    <td width="4%"> </td>
    <td width="64%"><p><strong>
      Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model</strong><br>
      <u>Takuya Ohashi</u>, Yosuke Ikegami, Kazuki Yamamoto, Wataru Takano, Yoshihiko Nakamura<br>
      IROS,2018<br>
      <font color="#ff0000"><em><strong>Best Paper Award, Finalists</strong></em></font></br>
      <a href="http://www.ynl.t.u-tokyo.ac.jp/research/vmocap/">[Project page]</a> <a href="https://arxiv.org/pdf/1912.03880.pdf">[Paper]</a> <a href="https://www.youtube.com/watch?v=hakyUz3_SD4">[Video]</a></p></td>
    <td>&nbsp;</td>
    </tr>


</tbody></table>
<p><a href="https://scholar.google.co.jp/citations?user=kR0Dxl0AAAAJ">[Google Scholar]</a></p>
<br>


<p>経歴</p>
<hr>
<ul>
<li><span style="font-size: medium;">2021年1月 - 現在: ソニー株式会社 R&Dセンター 基盤技術研究開発フィールド Tokyo Laboratory 19</span></li>
<li><span style="font-size: medium;">2018年11月 - 2020年12月: 東京大学 大学院情報理工学系研究科 知能機械情報学専攻 共同研究員</span></li>
<li><span style="font-size: medium;">2018年4月 - 2020年12月: 株式会社 NTTドコモ R&Dイノベーション本部 サービスイノベーション部</span></li>
<li><span style="font-size: medium;">2016年10月 - 2017年3月: ミュンヘン工科大学, Dept. of Electrical Engineering and Information Technology, 交換留学</span></li>
<li><span style="font-size: medium;">2015年10月 - 2018年3月: 東京大学 大学院情報理工学系研究科 知能機械情報学専攻 修士課程</span></li>
<li><span style="font-size: medium;">2015年4月 - 2015年9月: 東京工業大学 大学院理工学系研究科 機械制御システム専攻</span></li>
<li><span style="font-size: medium;">2011年4月 - 2015年3月: 東京工業大学 工学部 機械宇宙学科</span></li>
</ul>
<br clear="all">

<p>学位</p>
<hr>
<ul>
<li><span style="font-size: medium;">
修士 (情報理工学) 2018年3月 </span>
<ul>
  <li>東京大学 大学院情報理工学系研究科</li>
  <li>指導教員: 中村仁彦 教授</li>
</ul>
</li>
<li><span style="font-size: medium;">学士 (工学) 2015年3月 </span>
<ul>
  <li>東京工業大学 工学部</li>
  <li>指導教員: 山本貴富喜 准教授</li>
</ul>
</li>
</ul>
<br clear="all">


<p>受賞</p>
<hr>
<ul>
<li><span style="font-size: medium;">IROS 2018 Best Paper Award Finalists, 2018 <a href="https://www.iros2018.org/awards">[Link]</a></span></li>
<li><span style="font-size: medium;">日本機械学会三浦賞, 2018 <a href="https://www.jsme.or.jp/archive/award/miura-17.pdf">[Link]</a></span></li>
</ul>
<br clear="all">


<p>メディア掲載</p>
<hr>
<ul>
<li><span style="font-size: medium;">『子供の科学 4月号』: 複数人のモーションキャプチャをカメラ映像だけで行う!?, 2020 <a href="https://www.seibundo-shinkosha.net/magazine/kids/39165/">[Link]</a></span></li>
<li><span style="font-size: medium;">ITmedia NEWS (Seamless): カメラ映像から複数人の動きを骨格・筋レベルで同時検出　東大とドコモがモーションキャプチャ技術発表, 2020 <a href="https://www.itmedia.co.jp/news/articles/2001/30/news041.html">[Link]</a></span></li>
<li><span style="font-size: medium;">日経 xTECH special: あと１年に迫った5Gサービス開始 ドコモのイベントで未来を探ってみた, 2019 <a href="https://special.nikkeibp.co.jp/atclh/NXT/19/nttdocomov0118_01/p2/">[Link]</a></span></li>
<li><span style="font-size: medium;">毎日新聞: ＡＩで全身運動を即座に可視化　東大チーム開発, 2018 <a href="https://mainichi.jp/articles/20180531/ddm/016/040/005000c">[Link]</a></span></li>
<li><span style="font-size: medium;">Seamless: 東京大学など、複数台のRGBカメラだけから人のモーションキャプチャをリアルタイムに行う技術「VMocap」を発表, 2018 <a href="https://shiropen.com/seamless/vmocap">[Link]</a></span></li>
</ul>
<br clear="all">


<p>その他</p>
<hr>
<ul>
<li><span style="font-size: medium;"><a href="https://qiita.com/ohashi_zaemon">Qiita</a></span></li>
</ul>
<br clear="all">


</div></div>
