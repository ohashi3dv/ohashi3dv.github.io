<!DOCTYPE html>
<!-- saved from url=(0034)http://www.cs.toronto.edu/~slwang/ -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>Takuya Ohashi</title>
  <link href="./css/style.css" rel="stylesheet">
  <meta content='width=device-width,initial-scale=1' name='viewport'>
</head>


<div class="main">
<div class="container">
<section id="profile">
    <div style="text-align: right;">
    Japanese / <a href="./index.html">English</a>
    </div>
<div class="profile_left">
  <name>大橋拓也 (Takuya OHASHI)</name> </br></br>
  <u>所属</u></br>
    <li>株式会社 NTTドコモ</li>
    <li>東京大学 共同研究員</li>
</br>
  <u>研究分野</u></br>
      <li>コンピュータビジョン</li>
      <li>機械知能</li>
      <li>マーカーレスモーションキャプチャ</li></br>
  <u>連絡先</u></br>
    <span>Email: ohashi [at] ynl.t.u-tokyo.ac.jp</span></br>
    <span>Facebook: <a href="https://www.facebook.com/takuya.ohashi.084" target="_blank">takuya.ohashi.084</a></span>
</div>
<div class="profile_right">
</br><img src="./images/profile.jpg">
</div>
<div class="profile_bottom">
</div>
</section></br>

<p>研究プロジェクト</p><hr>
<table width="100%" border="0">
  <tbody>
    <tr>
    <td width="30%" class="crown-jewel"><img src="./images/vmocap.gif" width="240"></td>
    <td width="4%"> </td>
    <td width="65%"><p><strong>
        VMocap: realtime video motion capture and analysis of human movements </strong><br>
        Yoshihiko Nakamura, Yosuke Ikegami, <u>Takuya Ohashi</u>, Hiroki Obara<br>
        2018<br>
        <a href="https://www.youtube.com/watch?v=K_D2nGcht_k" target="_blank">[Video]</a> <a href="https://www.i.u-tokyo.ac.jp/news/pdf/news_20180515.pdf" target="_blank">[Press release]</a> </p></td>
    <td>&nbsp;</td>
    </tr>

    <tr>
    <td width="30%" class="crown-jewel"><img src="./images/vmocap-v1.gif" width="240"></td>
    <td width="4%"> </td>
    <td width="65%"><p><strong>
      Video Motion Capture from the Part Confidence Maps of Multi-Camera Images by Spatiotemporal Filtering Using the Human Skeletal Model</strong><br>
      <u>Takuya Ohashi</u>, Yosuke Ikegami, Kazuki Yamamoto, Wataru Takano, Yoshihiko Nakamura<br>
      IROS,2018<br>
      <font color="#ff0000"><em><strong>Best Paper Award, Finalists</strong></em></font></br>
      <a href="https://roboticsynl.github.io/vmocap/" target="_blank">[Project page]</a> <a href="https://arxiv.org/pdf/1912.03880.pdf" target="_blank">[Paper]</a> <a href="https://www.youtube.com/watch?v=hakyUz3_SD4" target="_blank">[Video]</a></p></td>
    <td>&nbsp;</td>
    </tr>


</tbody></table>
<p><a href="https://scholar.google.co.jp/citations?user=kR0Dxl0AAAAJ" target="_blank">[Google Scholor]</a></p>
<br>


<p>経歴</p>
<hr>
<ul>
<li><span style="font-size: medium;">2018年11月 - 現在: 東京大学大学院 情報理工学系研究科 知能機械情報学専攻 共同研究員</span></li>
<li><span style="font-size: medium;">2018年4月 - 現在: 株式会社 NTTドコモ R&Dイノベーション本部 サービスイノベーション部</span></li>
<li><span style="font-size: medium;">2016年10月 - 2017年3月: ミュンヘン工科大学, Dept. of Electrical Engineering and Information Technology, 交換留学</span></li>
<li><span style="font-size: medium;">2015年10月 - 2018年3月: 東京大学大学院 情報理工学系研究科 知能機械情報学専攻 修士課程</span></li>
<li><span style="font-size: medium;">2011年4月 - 2015年3月: 東京工業大学 工学部 機械宇宙学科</span></li>
</ul>
<br clear="all">

<p>学位</p>
<hr>
<ul>
<li><span style="font-size: medium;">
修士 (情報理工学) 2018年3月 </a></span>
<ul>
  <li>東京大学大学院</li>
  <li>指導教員: 中村仁彦 教授</li>
</ul>
</li>
<li><span style="font-size: medium;">学士 (工学) 2015年3月 </a></span>
<ul>
  <li>東京工業大学</li>
  <li>指導教員: 山本貴富喜 准教授</li>
</ul>
</li>
</ul>
<br clear="all">


<p>受賞</p>
<hr>
<ul>
<li><span style="font-size: medium;">IROS 2018 Best Paper Award, Finalists, 2018 <a href="https://www.iros2018.org/awards" target="_blank">[Link]</a></span></li>
<li><span style="font-size: medium;">日本機械学会三浦賞, 2017 <a href="https://www.jsme.or.jp/archive/award/miura-17.pdf" target="_blank">[Link]</a></span></li>
</ul>
<br clear="all">


<p>メディア掲載</p>
<hr>
<ul>
<li><span style="font-size: medium;">日経 xTECH special: あと１年に迫った5Gサービス開始 ドコモのイベントで未来を探ってみた, 2019 <a href="https://special.nikkeibp.co.jp/atclh/NXT/19/nttdocomov0118_01/p2/" target="_blank">[Link]</a></span></li>
<li><span style="font-size: medium;">毎日新聞: ＡＩで全身運動を即座に可視化　東大チーム開発, 2018 <a href="https://mainichi.jp/articles/20180531/ddm/016/040/005000c" target="_blank">[Link]</a></span></li>
<li><span style="font-size: medium;">Seamless: 東京大学など、複数台のRGBカメラだけから人のモーションキャプチャをリアルタイムに行う技術「VMocap」を発表, 2018 <a href="https://shiropen.com/seamless/vmocap" target="_blank">[Link]</a></span></li>
</ul>
<br clear="all">


<p>Others</p>
<hr>
<ul>
<li><span style="font-size: medium;"><a href="https://qiita.com/ohashi_zaemon" target="_blank">Qiita</a></span></li>
</ul>
<br clear="all">


</div></div>
